{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mod 2 Code Challenge Review\n",
    "\n",
    "You've come a long way with this material\n",
    "\n",
    "Close out strong\n",
    "\n",
    "![](viz/mortal_kombat.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis tests\n",
    "\n",
    "For each, write:\n",
    "\n",
    "- A null hypothesis \n",
    "- An alternative hypothesis\n",
    "- Specify an alpha level\n",
    "- Specify what Type I error and Type II error would be (in English, without reference to the words `null`, `hypothesis`, or `alternative`\n",
    "\n",
    "We have a scores from a given classroom and want to know how they compare to the rest of the district.  We have all of the district's information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null: There is no difference between scores in the given classroom and the scores of classrooms from all other districts\n",
    "Alternative: The scores are differente\n",
    "\n",
    "alpha: .05, with a two tailed test\n",
    "\n",
    "type 1 = WE conclude there is a difference in scores when in fact there is not.\n",
    "type 2 = We conclude there is no difference in scores when in fact there is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two samples of weights of fish from two adjacent lakes.  We want to know if Lake Winnetonka's fish are smaller than Lake Okachobee's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null: The weights of fish in Lake Winnetonka are greater than or equal to the weights in L O\n",
    "Alternative\n",
    "\n",
    "Type 1: Conclude the weights in Lake Winnetonka are smaller when in fact they are equal or greater\n",
    "Type 2: Conclude the weights are greater than or equal when in fact they are smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know if Guns 'n Roses rocks harder than Aerosmith, and are taking as a proxy \"noise levels = how hard a band rocks\".  We sample dB levels from 40 years of concerts.  Slash is looking over our shoulder the whole time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation Examples\n",
    "\n",
    "For each of the questions below:\n",
    "\n",
    "- What is the null hypothesis?  What is the alternative?\n",
    "\n",
    "- What level of alpha are we using?  \n",
    "\n",
    "\n",
    "- What specific test are we using?\n",
    "    - **why?**\n",
    "\n",
    "\n",
    "- What is the critical statistic(s) at which we will designate evidence for rejecting the null?\n",
    "\n",
    "- What is the test-statistic?\n",
    "\n",
    "- What is the p-value?\n",
    "\n",
    "- Should we accept or reject the null hypothesis?\n",
    "\n",
    "- In English, what's the answer to the question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-test example\n",
    "\n",
    "An SAT prep class of 25 students takes the SAT and gets the following scores:\n",
    "\n",
    "'''434 694 457 534 720 400 484 478 610 641 \n",
    "425 636 454 514 563 370 499 640 501 625 \n",
    "519 471 598 509 531 511 675 450 485 507 \n",
    "550 512 542 633 575 595 508 499 490 597 \n",
    "522 504 550 430 400'''\n",
    "We know the average for SAT scores as a whole is 500 with a standard deviation of 100\n",
    "\n",
    "Did this SAT prep class result in a significantly greater mean of scores than average?\n",
    "(use an alpha level of .05)\n",
    "\n",
    "[z-table](https://www.z-table.com) to use for calculations if you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null: The scores of students enrolled in the prep class are less than or equal to the greater population.\n",
    "Alt: The scores of the students enrolled in the prep class are greater than the greater population\n",
    "\n",
    "Alpha = .05\n",
    "\n",
    "Z-test, one tailed\n",
    "\n",
    "Z_stat = \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6448536269514722"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.norm.ppf(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.00053548386981"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = np.array(\"\"\"434 694 457 534 720 400 484 478 610 641 425 636 454 514 563 370 499 640 501 625 519 471 598 509 531 511 675 450 485 507 550 512 542 633 575 595 508 499 490 597 522 504 550 430 400\"\"\".split(' '))\n",
    "scores = scores.astype(int)\n",
    "\n",
    "(scores.mean() - 500)/(100/np.sqrt(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: T-test\n",
    "\n",
    "#### T-test question 1\n",
    "\n",
    "Samples of diastolic blood pressure were takin from a sample of 20 female doctors\n",
    "\n",
    "128 127 118 115 144 142 133 140 132 131 111 132 149 122 139 119 136 129 126 128\n",
    "\n",
    "The mean female population diastolic blood pressure is 120\n",
    "\n",
    "Are female doctor diastolic blood pressures significantly higher than the female population's?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.512403659336718"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = np.array('128 127 118 115 144 142 133 140 132 131 111 132 149 122 139 119 136 129 126 128'.split(' ')).astype(int)\n",
    "\n",
    "t = (bp.mean() - 120)/(bp.std(ddof=1)/np.sqrt(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.729132811521367"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.t.ppf(.95, df=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=4.512403659336718, pvalue=0.00023838063630967753)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(bp, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test question 2\n",
    "\n",
    "Tesla claims that they're miles-per-15min-of-charge average 31 \n",
    "\n",
    "You are hired by an eccentric Silicon Valley entreprenuer to test his fleet of 8 Teslas and see if the claim holds up\n",
    "\n",
    "You have a fair amount of driving around generating the data, and when you do you get these results:\n",
    "\n",
    "30 28 32 26 33 25 28 30\n",
    "\n",
    "Is Elon Musk a dirty liar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0367003088692623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04055343487369285"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null it is the same\n",
    "# Alternative they are different\n",
    "\n",
    "mpg = np.array('30 28 32 26 33 25 28 30'.split(' ')).astype(int)\n",
    "\n",
    "t = (mpg.mean() - 31)/((mpg.std(ddof=1)/np.sqrt(8)))\n",
    "print(t)\n",
    "\n",
    "stats.t.ppf(.05, df=7)\n",
    "stats.t.cdf(t, df=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=-2.0367003088692623, pvalue=0.0811068697473857)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(mpg, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test question 3\n",
    "\n",
    "You are an archeologist.  Not Indiana Jones, the boring kind.  And at two sites you come across a series of shards from pots.\n",
    "\n",
    "You know from your boring archeologist training that different thicknesses at the lip of the pots indicate different ceremonial functions.  \n",
    "\n",
    "You want to test the two samples of shard thickness to see if the thickness is due to chance at the two sites.\n",
    "\n",
    "Sample 1 has slightly thicker shards overall, so you want to test if the mean of sample 1 lip thickness is higher than the mean of sample 2 lip thickness.  \n",
    "\n",
    "Assume that the two sample variances are equal.\n",
    "\n",
    "Sample 1 data:\n",
    "19.7475 19.8387 12.6873 17.6973 19.0878 30.5562 14.5291 14.7627 14.3439 12.5745 11.0734 19.4998 18.3869 10.7374 18.0030 18.1730 18.8374 17.9287 15.3563 18.6004 11.7280 12.2898 21.0552 21.4184 25.5953\n",
    "\n",
    "Sample 2 data:\n",
    "17.4715 20.0386 12.6012 20.4401 22.4969 9.8613 19.6289 9.7741 15.1119 17.4448 23.4827 24.9357 19.9265 7.9955 17.6675 13.6029 17.8812 16.4178 5.1385 7.0984 18.1181 20.2681 14.7372 22.5915 16.7546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6557142942418951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0638985616280205"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = '''19.7475 19.8387 12.6873 17.6973 19.0878 30.5562 14.5291 14.7627 14.3439 12.5745 11.0734 19.4998 18.3869 10.7374 18.0030 18.1730 18.8374 17.9287 15.3563 18.6004 11.7280 12.2898 21.0552 21.4184 25.5953'''.split(' ')\n",
    "s1 = np.array(s1, float)\n",
    "\n",
    "s2 = '''17.4715 20.0386 12.6012 20.4401 22.4969 9.8613 19.6289 9.7741 15.1119 17.4448 23.4827 24.9357 19.9265 7.9955 17.6675 13.6029 17.8812 16.4178 5.1385 7.0984 18.1181 20.2681 14.7372 22.5915 16.7546'''.split(' ')\n",
    "s2 = np.array(s2, float)\n",
    "\n",
    "num = (s1.mean() - s2.mean())\n",
    "pooled_v = (s1.var(ddof=1) + s2.var(ddof=1))/2\n",
    "denom = np.sqrt(pooled_v) * np.sqrt(2/len(s2))\n",
    "t = num/denom\n",
    "print(t)\n",
    "stats.t.ppf(.975, df=(len(s1)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8720077739881615"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.std()/s2.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.655714294241895, pvalue=0.5151387607057331)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test question 4\n",
    "\n",
    "Two sets of female rats were given a high- and low-protein diet, respectively, after giving birth.  Their weights were measured after 2 months.\n",
    "\n",
    "Set 1 (high protein) = 134 146 104 119 124 161 107 83 113 129 97 123\n",
    "\n",
    "Set 2 (low protein) = 70 118 101 85 107 132 94\n",
    "\n",
    "Is there a difference in rat weight between high- and low-protein diets after giving birth in this experiment?\n",
    "(Assume the sample variances are equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '134 146 104 119 124 161 107 83 113 129 97 123'.split(' ')\n",
    "s1 = np.array(s1, int)\n",
    "s2 = \"70 118 101 85 107 132 94\".split(' ')\n",
    "s2 = np.array(s2, int)\n",
    "\n",
    "num = s1.mean() - s2.mean()\n",
    "pooled = ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-test question 5\n",
    "\n",
    "Get a wee bit of practice w/ pandas again, eh?\n",
    "\n",
    "Back to the data about Seattle city service `hourly_rate` compensation\n",
    "\n",
    "There's a national debate about whether construction workers or HR people account for more \"bloat\" in the system.  Construciton workers argue that there are a higher percentage of \"junior\" positions in their departments, while HR people have more \"senior\" positions.  \n",
    "\n",
    "Let's test that with the Seattle data.\n",
    "\n",
    "Create a dataframe of:\n",
    "- jobs in the `Construction and Inspections` dept\n",
    "- jobs in the `Human Services Dept` . . . dept\n",
    "- that don't have `Sr` as the last two letters in their title\n",
    "\n",
    "Sample 50 junior employees from each department (`random_state=33`)\n",
    "\n",
    "Use those employees to provide evidence for the question: do junior employees in construction departments have different `hourly_rate` compensation than those in HR departments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Police Department                 2016\n",
       "Seattle City Light                1731\n",
       "Parks & Recreation                1440\n",
       "Seattle Public Utilities          1409\n",
       "Fire Department                   1083\n",
       "Seattle Dept of Transportation    1017\n",
       "Information Technology             716\n",
       "Finance & Admin Services           585\n",
       "Seattle Center                     566\n",
       "Human Services Department          387\n",
       "Construction & Inspections         384\n",
       "Legislative Department             108\n",
       "Seattle Dept of Human Resource     101\n",
       "Education & Early Learning          96\n",
       "Neighborhoods                       61\n",
       "Arts & Culture                      47\n",
       "Planning & Comm Development         46\n",
       "Office of Housing                   44\n",
       "City Budget Office                  42\n",
       "Mayor's Office                      37\n",
       "Office of Economic Development      37\n",
       "Sustainability & Environment        33\n",
       "Office for Civil Rights             31\n",
       "Employees' Retirement System        31\n",
       "Office of Labor Standards           24\n",
       "City Auditor                        12\n",
       "Office of Inspector General          9\n",
       "Immigrant & Refugee Affairs          9\n",
       "Civil Service Commissions            9\n",
       "Intergovernment Relations            8\n",
       "Ethics & Elections Commission        7\n",
       "Community Police Commission          5\n",
       "Office of Employee OMBUD             4\n",
       "Police Relief & Pension Fund         4\n",
       "Hearing Examiner                     4\n",
       "Name: department, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/data.csv')\n",
    "df.department.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60.337, 33.44 , 36.71 , 36.71 , 51.812, 36.71 , 36.71 , 45.14 ,\n",
       "       31.56 , 25.22 , 25.22 , 22.53 , 36.71 , 32.75 , 31.56 , 27.12 ,\n",
       "       24.78 , 33.44 , 31.56 , 31.56 , 28.11 , 28.11 , 33.4  , 36.71 ,\n",
       "       34.66 , 31.56 , 71.194, 45.14 , 32.75 , 31.56 , 28.11 , 31.56 ,\n",
       "       26.16 ])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_construction = df[(df.department == 'Construction & Inspections') & (~df.job_title.str.contains('Sr'))]\n",
    "s_con = np.random.choice(df_construction.hourly_rate, 33)\n",
    "df_human = df[(df.department == 'Human Services Department') & (~df.job_title.str.contains('Sr'))]\n",
    "s_human = np.random.choice(df_human.hourly_rate, 33)\n",
    "s_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Welsh's t, ie ttest_ind(equal_var=False), has some proseltyzors](https://onlinelibrary.wiley.com/doi/abs/10.1348/000711004849222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
